{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9537453-87ad-43b2-911c-0c5cb9b659d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D,Input\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63480176-f719-45ca-b18f-924e725cf7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afbe3af6-45c7-4498-83b6-0f86244523b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "293eb27b-5862-4374-bfc5-4eba175ccb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy completed\n",
      "sad completed\n",
      "fear completed\n",
      "surprise completed\n",
      "neutral completed\n",
      "angry completed\n",
      "disgust completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1de37aab-2ad5-4a2f-b08e-fe63203009da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image    label\n",
      "0         images/train/happy/3578.jpg    happy\n",
      "1        images/train/happy/16988.jpg    happy\n",
      "2         images/train/happy/2666.jpg    happy\n",
      "3         images/train/happy/5109.jpg    happy\n",
      "4        images/train/happy/11981.jpg    happy\n",
      "...                               ...      ...\n",
      "28816  images/train/disgust/10112.jpg  disgust\n",
      "28817  images/train/disgust/21668.jpg  disgust\n",
      "28818   images/train/disgust/7049.jpg  disgust\n",
      "28819   images/train/disgust/9716.jpg  disgust\n",
      "28820   images/train/disgust/3561.jpg  disgust\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1293229d-6a2f-4c6e-8f03-464eb4aa1e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy completed\n",
      "sad completed\n",
      "fear completed\n",
      "surprise completed\n",
      "neutral completed\n",
      "angry completed\n",
      "disgust completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c927460-0daa-4ddb-b4f3-cade3c6d7cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image    label\n",
      "0       images/test/happy/23933.jpg    happy\n",
      "1       images/test/happy/24906.jpg    happy\n",
      "2       images/test/happy/18033.jpg    happy\n",
      "3       images/test/happy/15271.jpg    happy\n",
      "4       images/test/happy/26888.jpg    happy\n",
      "...                             ...      ...\n",
      "7061  images/test/disgust/20761.jpg  disgust\n",
      "7062  images/test/disgust/28710.jpg  disgust\n",
      "7063  images/test/disgust/23876.jpg  disgust\n",
      "7064   images/test/disgust/9460.jpg  disgust\n",
      "7065  images/test/disgust/35580.jpg  disgust\n",
      "\n",
      "[7066 rows x 2 columns]\n",
      "0         images/test/happy/23933.jpg\n",
      "1         images/test/happy/24906.jpg\n",
      "2         images/test/happy/18033.jpg\n",
      "3         images/test/happy/15271.jpg\n",
      "4         images/test/happy/26888.jpg\n",
      "                    ...              \n",
      "7061    images/test/disgust/20761.jpg\n",
      "7062    images/test/disgust/28710.jpg\n",
      "7063    images/test/disgust/23876.jpg\n",
      "7064     images/test/disgust/9460.jpg\n",
      "7065    images/test/disgust/35580.jpg\n",
      "Name: image, Length: 7066, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de2dc832-6e6d-46d8-8117-0108e04fb486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3721cb79-76ab-44dd-a5d9-76e10f35a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image,grayscale =  True )\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d767d3e4-b049-480f-a118-5e07ac4116e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82f864d858a4fd3893eb7f5dfaa3d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kartikay/miniconda3/lib/python3.11/site-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "train_features = extract_features(train['image']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03717076-da35-4fdb-aca5-766a8fb8d924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60e39215ab94e01b2d2446d2b0ddeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc8c2936-372c-4425-87d7-7e298beaaf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fda2400-fe6b-4f50-9be1-1c51f9040116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51725f34-3c40-4d04-b8f0-edf29920039d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46e4ebaf-c7f3-4750-afff-ad7631dfbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39464081-0c0a-456f-98b8-90ff1da31587",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7d79e1e-0156-4917-b191-ac6c63367eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kartikay/miniconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "t = to_categorical(y_test,num_classes = 7)\n",
    "model = Sequential()\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1393aae-97d0-44f2-94a8-3a5c5b2a5213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "011ce8ff-e029-4b6b-a364-e3a196204e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 17/226\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 780ms/step - accuracy: 0.1905 - loss: 1.8819"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39m x_train,y \u001b[38;5;241m=\u001b[39m y_train, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, validation_data \u001b[38;5;241m=\u001b[39m (x_test,y_test))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x= x_train,y = y_train, batch_size = 128, epochs = 100, validation_data = (x_test,y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb29e92d-2347-476a-8e6d-2f0180471a75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 855ms/step - accuracy: 0.2424 - loss: 1.8248 - val_accuracy: 0.2588 - val_loss: 1.7959\n",
      "Epoch 2/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 925ms/step - accuracy: 0.2539 - loss: 1.7945 - val_accuracy: 0.3002 - val_loss: 1.7089\n",
      "Epoch 3/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 2s/step - accuracy: 0.3115 - loss: 1.7007 - val_accuracy: 0.4169 - val_loss: 1.5106\n",
      "Epoch 4/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 1s/step - accuracy: 0.3894 - loss: 1.5530 - val_accuracy: 0.4550 - val_loss: 1.4224\n",
      "Epoch 5/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 969ms/step - accuracy: 0.4204 - loss: 1.4895 - val_accuracy: 0.4741 - val_loss: 1.3537\n",
      "Epoch 6/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 1s/step - accuracy: 0.4455 - loss: 1.4301 - val_accuracy: 0.5017 - val_loss: 1.2851\n",
      "Epoch 7/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 1s/step - accuracy: 0.4640 - loss: 1.3863 - val_accuracy: 0.5146 - val_loss: 1.2546\n",
      "Epoch 8/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 865ms/step - accuracy: 0.4840 - loss: 1.3478 - val_accuracy: 0.5256 - val_loss: 1.2490\n",
      "Epoch 9/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 962ms/step - accuracy: 0.4935 - loss: 1.3227 - val_accuracy: 0.5391 - val_loss: 1.2169\n",
      "Epoch 10/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 890ms/step - accuracy: 0.4992 - loss: 1.3094 - val_accuracy: 0.5352 - val_loss: 1.2067\n",
      "Epoch 11/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 890ms/step - accuracy: 0.5127 - loss: 1.2780 - val_accuracy: 0.5498 - val_loss: 1.1787\n",
      "Epoch 12/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 863ms/step - accuracy: 0.5163 - loss: 1.2707 - val_accuracy: 0.5545 - val_loss: 1.1642\n",
      "Epoch 13/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 878ms/step - accuracy: 0.5223 - loss: 1.2486 - val_accuracy: 0.5623 - val_loss: 1.1649\n",
      "Epoch 14/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 864ms/step - accuracy: 0.5332 - loss: 1.2310 - val_accuracy: 0.5611 - val_loss: 1.1565\n",
      "Epoch 15/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 852ms/step - accuracy: 0.5401 - loss: 1.2148 - val_accuracy: 0.5692 - val_loss: 1.1348\n",
      "Epoch 16/100\n",
      "\u001b[1m 34/226\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:38\u001b[0m 823ms/step - accuracy: 0.5543 - loss: 1.1801"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39m x_train,y \u001b[38;5;241m=\u001b[39m y_train, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, validation_data \u001b[38;5;241m=\u001b[39m (x_test,y_test))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x= x_train,y = y_train, batch_size = 128, epochs = 100, validation_data = (x_test,y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60a1c655-f703-4fbe-9383-5342549e3d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "821fa936-d997-4c77-a3cb-ed2f24df1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a1fb559-7ca0-4114-ac7d-dec3a383e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbaa6a06-46d2-44f0-8283-d57cf921f056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kartikay/miniconda3/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 16 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "json_file = open(\"emotiondetector.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"emotiondetector.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c416ba6f-cba5-4f2f-b13c-9377385ae3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94484f68-d30c-47e0-ab18-a822ea52644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image,grayscale =  True )\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b111a254-449a-4892-bd91-83a4db232880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "model prediction is  sad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kartikay/miniconda3/lib/python3.11/site-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24388a2e-cf1b-4b92-875b-f5acd58281cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "model prediction is  sad\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m pred_label \u001b[38;5;241m=\u001b[39m label[pred\u001b[38;5;241m.\u001b[39margmax()]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel prediction is \u001b[39m\u001b[38;5;124m\"\u001b[39m,pred_label)\n\u001b[0;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m48\u001b[39m,\u001b[38;5;241m48\u001b[39m),cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e083bbe8-a12a-4d76-87ad-4d8dd0d4fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12a46723-9d6a-4e31-9dc7-0460639ed57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "model prediction is  sad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kartikay/miniconda3/lib/python3.11/site-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x30fa80890>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc46e0f-4e65-4c33-93be-8e5ae331b474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
